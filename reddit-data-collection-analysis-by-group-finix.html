<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="MFIN7036 Students 2024" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group FINIX, Progress Report, " />

<meta property="og:title" content="Reddit Data Collection &amp; Analysis (By Group &#34;FINIX&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/reddit-data-collection-analysis-by-group-finix.html" />
<meta property="og:description" content="Abstract This is a post reporting our current process on collecting data from Reddit. In this stage, our objective is to collect enough data and store them into files for future analysis. During the collection process, we encountered several problems and give some possible solutions. Data Collection We are trying …" />
<meta property="og:site_name" content="MFIN7036 Student Blog 2024" />
<meta property="og:article:author" content="MFIN7036 Students 2024" />
<meta property="og:article:published_time" content="2024-03-04T11:30:00+08:00" />
<meta name="twitter:title" content="Reddit Data Collection &amp; Analysis (By Group &#34;FINIX&#34;) ">
<meta name="twitter:description" content="Abstract This is a post reporting our current process on collecting data from Reddit. In this stage, our objective is to collect enough data and store them into files for future analysis. During the collection process, we encountered several problems and give some possible solutions. Data Collection We are trying …">

        <title>Reddit Data Collection &amp; Analysis (By Group &#34;FINIX&#34;)  · MFIN7036 Student Blog 2024
</title>
        <link href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MFIN7036 Student Blog 2024 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/"><span class=site-name>MFIN7036 Student Blog 2024</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/MFIN7036-student-blog-2024-02
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/reddit-data-collection-analysis-by-group-finix.html">
                Reddit Data Collection & Analysis (By Group "FINIX")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <h1>Abstract</h1>
<p>This is a post reporting our current process on collecting data from Reddit. In this stage, our objective is to collect enough data and store them into files for future analysis. During the collection process, we encountered several problems and give some possible solutions. </p>
<h2>Data Collection</h2>
<p>We are trying to gather data from Reddit. Generally, we are focusing on titles of posts and bodies of comments related to AI companies from the subreddit <strong>"r/wallstreetbets"</strong> .</p>
<blockquote>
<p>​ <strong>r/wallstreetbets</strong>, also known as <strong>WallStreetBets</strong> or <strong>WSB</strong>, is a subreddit where participants discuss stocks and option trading. It has become notable for its colorful and profane jargon, aggressive trading strategies, and for playing a major role in the GameStop short squeeze that caused losses for some US firms and short sellers in a few days in early 2021.</p>
</blockquote>
<p>Reddit API allows us to retrieve update-to-date post and comment data. Prior to fetching the data, we need to create a Reddit account and then register an application to obtain API credentials (<strong>client ID</strong> and <strong>client secret</strong>) from <a href="https://www.reddit.com/prefs/apps">preferences (reddit.com)</a>. </p>
<p><img alt="Alt Text" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/group-FINIX_01_image-RedditCredential.jpg"></p>
<p><strong>PRAW</strong> is used to access Reddit's API. It send HTTP requests to Reddit’s API endpoints, specifying the necessary parameters such as subreddit name, sort type, time range, etc., depending on the data we want to fetch.</p>
<p>These credentials are used to authenticate the requests. Below is the Python code for setting up our API autentication:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">praw</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="c1">#initialize the identification</span>
<span class="n">reddit</span> <span class="o">=</span> <span class="n">praw</span><span class="o">.</span><span class="n">Reddit</span><span class="p">(</span><span class="n">client_id</span><span class="o">=</span><span class="s1">&#39;client id&#39;</span><span class="p">,</span>
                     <span class="n">client_secret</span><span class="o">=</span><span class="s1">&#39;client secret&#39;</span><span class="p">,</span>
                     <span class="n">user_agent</span><span class="o">=</span><span class="s1">&#39;define by ourselves. e.g. Steve&#39;</span><span class="p">)</span>
</code></pre></div>

<p>We focus only on the comments rather than the posts. We will discuss the reasons behind that in the following parts. The information collected includes the 'title', 'score', 'created_utc','comments'. They each represents:</p>
<table>
<thead>
<tr>
<th>attribute</th>
<th>description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>title</strong></td>
<td>The title of the post. This is the primary identifier of the post, usually summarizing its content or theme.</td>
</tr>
<tr>
<td><strong>score</strong></td>
<td>The score of the post. This is the number of upvotes minus the number of downvotes the post has received. A higher score typically indicates content that the community members find more favorable or valuable.</td>
</tr>
<tr>
<td><strong>created_utc</strong></td>
<td>The UTC timestamp when the post was created. This timestamp indicates when the post was made on Reddit. This attribute can be used to understand the timeliness of the post or for analyzing the distribution of posts over time.</td>
</tr>
<tr>
<td><strong>comments</strong></td>
<td>This attribute allows access to posts' comments.</td>
</tr>
</tbody>
</table>
<p>To do this job, we write the following function. It searches the top 10 posts (by default) in <em>topic</em> from subreddit <em>subreddit_name</em> and get the first direct 20 comments from of the posts (i.e. no comments of comments here). </p>
<div class="highlight"><pre><span></span><code><span class="nv">def</span><span class="w"> </span><span class="nv">get_posts</span><span class="ss">(</span><span class="nv">subreddit_name</span>,<span class="w"> </span><span class="nv">topic</span>,<span class="w"> </span><span class="nv">limit</span><span class="o">=</span><span class="mi">10</span>,<span class="w"> </span><span class="nv">comment_limit</span><span class="o">=</span><span class="mi">20</span><span class="ss">)</span>:
<span class="w">    </span><span class="nv">subreddit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">reddit</span>.<span class="nv">subreddit</span><span class="ss">(</span><span class="nv">subreddit_name</span><span class="ss">)</span>
<span class="w">    </span><span class="nv">posts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>[]
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nv">post</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">subreddit</span>.<span class="nv">search</span><span class="ss">(</span><span class="nv">topic</span>,<span class="nv">limit</span><span class="o">=</span><span class="nv">limit</span><span class="ss">)</span>:
<span class="w">        </span><span class="nv">post_info</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>{
<span class="w">            </span><span class="s1">&#39;title&#39;</span>:<span class="w"> </span><span class="nv">post</span>.<span class="nv">title</span>,
<span class="w">            </span><span class="s1">&#39;score&#39;</span>:<span class="w"> </span><span class="nv">post</span>.<span class="nv">score</span>,
<span class="w">            </span><span class="s1">&#39;created_utc&#39;</span>:<span class="w"> </span><span class="nv">post</span>.<span class="nv">created_utc</span>,
<span class="w">            </span><span class="s1">&#39;comments&#39;</span>:<span class="w"> </span>[]
<span class="w">        </span>}
<span class="w">        </span><span class="nv">post</span>.<span class="nv">comments</span>.<span class="nv">replace_more</span><span class="ss">(</span><span class="nv">limit</span><span class="o">=</span><span class="mi">0</span><span class="ss">)</span><span class="w">  </span>#<span class="w"> </span><span class="nv">Keep</span><span class="w"> </span><span class="nv">direct</span><span class="w"> </span><span class="nv">comments</span>，<span class="nv">drop</span><span class="w"> </span><span class="nv">comments</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">comments</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="nv">comment</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">post</span>.<span class="nv">comments</span>[:<span class="nv">comment_limit</span>]:<span class="w">  </span>#<span class="w"> </span><span class="nv">Keep</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">top</span><span class="w"> </span><span class="mi">20</span><span class="w"> </span><span class="nv">comments</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">posts</span>.
<span class="w">            </span><span class="nv">comment_info</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>{
<span class="w">                </span><span class="s1">&#39;body&#39;</span>:<span class="w"> </span><span class="nv">comment</span>.<span class="nv">body</span>,
<span class="w">                </span><span class="s1">&#39;score&#39;</span>:<span class="w"> </span><span class="nv">comment</span>.<span class="nv">score</span>
<span class="w">            </span>}
<span class="w">            </span><span class="nv">post_info</span>[<span class="s1">&#39;comments&#39;</span>].<span class="nv">append</span><span class="ss">(</span><span class="nv">comment_info</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">posts</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">post_info</span><span class="ss">)</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nv">posts</span>
</code></pre></div>

<p>This is a sample code used to retrieve AI-related posts from <em>wallstreetbets</em> subreddit. The timestamp of raw data is in <a href="https://en.wikipedia.org/wiki/Unix_time"><em>Unix time</em></a> format. In order to better recognize the submission times of posts, we convert the <em>Unix</em> timestamp into human-redable <a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time"><em>UTC</em></a> timestamp. </p>
<div class="highlight"><pre><span></span><code><span class="nv">subreddit_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;wallstreetbets&#39;</span>
<span class="nv">topic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;AI&#39;</span>
<span class="nv">posts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">get_posts</span><span class="ss">(</span><span class="nv">subreddit_name</span>,<span class="nv">topic</span>,<span class="nv">limit</span><span class="w"> </span><span class="o">=</span><span class="mi">200000</span>,<span class="nv">comment_limit</span><span class="o">=</span><span class="mi">50</span><span class="ss">)</span>

<span class="nv">comments_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>[<span class="ss">(</span><span class="nv">post</span>[<span class="s1">&#39;title&#39;</span>],<span class="w"> </span><span class="nv">time</span>.<span class="nv">strftime</span><span class="ss">(</span><span class="s1">&#39;%Y-%m-%d&#39;</span>,<span class="w"> </span><span class="nv">time</span>.<span class="nv">localtime</span><span class="ss">(</span><span class="nv">post</span>[<span class="s1">&#39;created_utc&#39;</span>]<span class="ss">))</span>,<span class="nv">comment</span>[<span class="s1">&#39;body&#39;</span>],<span class="w"> </span><span class="nv">comment</span>[<span class="s1">&#39;score&#39;</span>]<span class="ss">)</span><span class="w"> </span>
<span class="w">                 </span><span class="k">for</span><span class="w"> </span><span class="nv">post</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">posts</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">comment</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">post</span>[<span class="s1">&#39;comments&#39;</span>]]
<span class="nv">df_comments</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">pd</span>.<span class="nv">DataFrame</span><span class="ss">(</span><span class="nv">comments_data</span>,<span class="w"> </span><span class="nv">columns</span><span class="o">=</span>[<span class="s1">&#39;Post Title&#39;</span>,<span class="w"> </span><span class="s1">&#39;Post Time&#39;</span>,<span class="w"> </span><span class="s1">&#39;Comment Body&#39;</span>,<span class="w"> </span><span class="s1">&#39;Score&#39;</span>]<span class="ss">)</span>
</code></pre></div>

<p>Below is some of the data collected, we format it into the following dataframe structure. It is then  we storge Reddit data as <em>csv</em> files locally for future use. For those topics, we will collect data of both posts and the stock price.</p>
<p><img alt="Dataset" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/group-FINIX_01_image_image-partialdataset.jpg"></p>
<p>In our project, we identify the following terms as topics. Both stock prices and Reddit data related to these topics will be futher collected.
- <strong>AI related Company:</strong> Microsoft, Google, NVIDIA, AMD...
- <strong>AI Model:</strong> ChatGPT, Gemini, Sora, Diffusion...
- <strong>Index:</strong> NSDQ</p>
<h2>Key Points To Note</h2>
<h4>1. Choice of post contents</h4>
<p>At the beginning, we tried to use both the <strong>body text of both posts and comments</strong> to analyze, but after we browse some posts, we found that many of them:</p>
<ul>
<li><strong>Too long:</strong> some posts contains more than 10k words</li>
<li><strong>Provide limited sentiment information:</strong> some posts provide research data or news which are relatively neutral in sentiment</li>
<li><strong>Only a picture/video in the post (meme):</strong> which we cannot obtain any textual data from the posts</li>
</ul>
<p>As such, we decide to use only post title to identify topics, and comment body of each post for the sentiment analysis.</p>
<h4>2. Choice of Subreddits</h4>
<p>Originally, we plan to use AI companies' subreddits to search for data, such as NVIDIA, Google, etc. However, many posts in those subreddits are not all closely related to the stock. We believe those posts and comments can post bias when we analyze the stock market sentiment.</p>
<p>We decide to abort this idea and turn to "r/wallstreetbets", which consists tons of discussion on stock markets. Then, we choice the specific topics to collect posts and comments.</p>
<h2>Problems to be solved</h2>
<h4>1. USELESS Comments</h4>
<p>When fetching data via Reddit API, there are some unstructured comments that are unrelated to posts, like this: </p>
<blockquote>
<p><code>'\n**User Report**| | | |\n:--|:--|:--|:--\n**Total Submissions** | 1 | **First Seen In WSB** | 5 months ago\n**Total Comments** | 40 | **Previous Best DD** | \n**Account Age** | 3 years | | \n\n[**Join WSB Discord**](http://discord.gg/wsbverse)'</code>
These appear to be messages sent by robot, which could generate noise for our analysis. Thus we intend to use regular expression to filter the noisy data. </p>
</blockquote>
<h4>2. EMOJI</h4>
<p>The emojis can better reflect the one's sentiment and attitude. However, the derived emojis appear in the following format, where we cannot extract any meaningful textual information. Another consideration is, the emotional meanings of emojis can vary depending on culture, context, and personal interpretation.</p>
<blockquote>
<p><code>![img](emote|t5_2th52|4271)'</code></p>
</blockquote>
<p>We may explore several methods to deal with emojis:
- Create a emoji map (use of regular expression) for mapping the Unicode emojis to the related emotion
- Use the Python package <strong>demoji</strong> to remove emoji in comments</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2024-03-04T11:30:00+08:00">Mon 04 March 2024</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/categories.html#progress-report-ref">Progress Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/tags.html#group-finix-ref">Group FINIX
                    <span class="superscript">2</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/MFIN7036-student-blog-2024-02" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>