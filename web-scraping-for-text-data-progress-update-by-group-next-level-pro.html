<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="MFIN7036 Students 2024" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Next Level Pro, Progress Report 1, " />

<meta property="og:title" content="Web Scraping for Text Data &amp; Progress Update (by Group &#34;Next Level Pro&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/web-scraping-for-text-data-progress-update-by-group-next-level-pro.html" />
<meta property="og:description" content="Recalling from our previous presentation, our group intend to utilize the news articles related to NVIDIA available online, convert those text data into numerical data by sentiment analylsis, and use this data to predict the volatility of NVIDIA. In kickstart our project, the first and major step is web scraping …" />
<meta property="og:site_name" content="MFIN7036 Student Blog 2024" />
<meta property="og:article:author" content="MFIN7036 Students 2024" />
<meta property="og:article:published_time" content="2024-03-03T21:00:00+08:00" />
<meta name="twitter:title" content="Web Scraping for Text Data &amp; Progress Update (by Group &#34;Next Level Pro&#34;) ">
<meta name="twitter:description" content="Recalling from our previous presentation, our group intend to utilize the news articles related to NVIDIA available online, convert those text data into numerical data by sentiment analylsis, and use this data to predict the volatility of NVIDIA. In kickstart our project, the first and major step is web scraping …">

        <title>Web Scraping for Text Data &amp; Progress Update (by Group &#34;Next Level Pro&#34;)  · MFIN7036 Student Blog 2024
</title>
        <link href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MFIN7036 Student Blog 2024 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/"><span class=site-name>MFIN7036 Student Blog 2024</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/MFIN7036-student-blog-2024-02
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/web-scraping-for-text-data-progress-update-by-group-next-level-pro.html">
                Web Scraping for Text Data & Progress Update (by Group "Next Level Pro")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>Recalling from our previous presentation, our group intend to utilize the news articles related to <strong>NVIDIA</strong> available online, convert those text data into numerical data by sentiment analylsis, and use this data to predict the volatility of NVIDIA. In kickstart our project, the first and major step is web scraping.</p>
<p>Web scraping is a technique used to extract data from websites. It involves programmatically accessing and retrieving specific information from web pages. In the context of financial research, web scraping allows us to gather a wealth of textual information from news websites.</p>
<p>However, scraping articles from news websites can be complicated. Many websites use dynamic loading, where content is loaded dynamically as the user scrolls or interacts with the page, but the link to this page is not changed. This poses a challenge when attempting to retrieve all the desired data, as the entire page content may not be readily available in the initial HTML response.</p>
<p>In this blog post, we will focus on showcasing our works on scraping the data from CNBC, Yahoo and Washington Post, by demonstrating how to find the links to the articles related to our target company/collecting the text data required. </p>
<h1>CNBC</h1>
<h2>Observing the page</h2>
<p>Searching for <a href="https://www.cnbc.com/search/?query=nvidia&amp;qsearchterm=nvidia">NVIDIA on the CNBC website</a>, it can be observed that only a portion of the article titles and summaries are displayed initially. As the page is scrolled to the bottom, a new set of articles appears, as showing below.</p>
<p><em>Before loading</em>:</p>
<p><img alt="Figure 1" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/NextLevelPro_01_01CNBCbeforeloading.jpg"></p>
<p><em>After loading</em>:</p>
<p><img alt="Figure 2" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/NextLevelPro_01_02CNBCafterloading.jpg"></p>
<p>Inspecting the source code we could also find that, the links for all articles are not available at the first glance, which makes it impractical to simply scrape the web source code to obtain link information. </p>
<h2>Network inspecting</h2>
<p>After several trials, we figured out how to extract news links in bulk from dynamically loaded pages by inspecting information under the Network tool. While we discovered certain specific patterns for this website, the general approach can be applied to similar cases.</p>
<p>First, click on "Network" and filter out the files whose name contain "aspx". As shown in the screenshot, before loading more webpage content, there are only two files visible. However, after loading more content, the number of files in this section increases accordingly.</p>
<p><em>Before loading</em>:</p>
<p><img alt="Figure 3" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/NextLevelPro_01_03CNBCbeforeloading_Network.jpg"></p>
<p><em>After loading</em>:</p>
<p><img alt="Figure 4" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/NextLevelPro_01_04CNBCafterloading_Network.jpg"></p>
<p>Click on "Preview" and expand the "results" section. Here, we can see the links of the newly loaded articles, neatly arranged in groups of ten. </p>
<p><img alt="Figure 5" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/NextLevelPro_01_05CNBCPreview.jpg"></p>
<p>We then go back to "Headers", where "Request URL" is shown. Open it we can find a page containing all ten links to the articles loaded this single time. So this url is what we want. Further explore the structure of the url, we could find that all of them just differ in one number, which start form 0 and increment by 10 each time. </p>
<p><img alt="Figure 6" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/NextLevelPro_01_06CNBCHeaders.jpg"></p>
<h2>Code for scraping links to news</h2>
<p>With this pattern, we can move to the code to scrape the links. By employing a simple loop structure, we can obtain a substantial number of website URLs containing news links. Using regular expression, we can extract the links for news articles.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">requests</span><span class="o">.</span><span class="n">packages</span><span class="o">.</span><span class="n">urllib3</span><span class="o">.</span><span class="n">disable_warnings</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">status_check</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">agent</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span><span class="s1">&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.79 Safari/537.36&#39;</span><span class="p">}</span>

    <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span> <span class="o">=</span> <span class="n">agent</span><span class="p">,</span> <span class="n">verify</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">resp</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span> <span class="o">=</span> <span class="n">agent</span><span class="p">,</span> <span class="n">verify</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="k">return</span> <span class="kc">False</span>

<span class="n">linkpattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;&quot;url&quot;:&quot;(https:\/\/www\.cnbc\.com\/\d+\/.*?)&quot;,&quot;@id&quot;&#39;</span>
<span class="n">links1</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">indi</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">10</span><span class="o">*</span><span class="n">i</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://api.queryly.com/cnbc/json.aspx?queryly_key=31a35d40a9a64ab3&amp;query=nvidia&amp;endindex=&#39;</span> \
        <span class="o">+</span> <span class="n">indi</span> \
        <span class="o">+</span> <span class="s1">&#39;&amp;batchsize=10&amp;callback=&amp;showfaceted=false&amp;timezoneoffset=-480&amp;facetedfields=formats&amp;facetedkey=formats%7C&amp;facetedvalue=!Press%20Release%7C&amp;additionalindexes=4cd6f71fbf22424d,937d600b0d0d4e23,3bfbe40caee7443e,626fdfcd96444f28&#39;</span>
    <span class="k">if</span> <span class="n">status_check</span><span class="p">(</span><span class="n">url</span><span class="p">)</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">status_check</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">link</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">linkpattern</span><span class="p">,</span> <span class="n">content</span><span class="p">)</span>
        <span class="n">links1</span> <span class="o">+=</span> <span class="n">link</span>

    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>

<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">((</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="mi">60</span><span class="p">)</span>
</code></pre></div>

<p>It is important to note that the above code is designed to help us retrieve news articles in textual form, excluding videos. However, the titles of videos can also play a role in sentiment analysis. Additionally, there may be some articles that require a membership to read, but their titles can still be valuable. We will consider addressing these situations in the later stages.</p>
<h1>Yahoo</h1>
<h2>Scraper on Github</h2>
<p>We were able to find a <a href="https://github.com/israel-dryer/Yahoo-News-Scraper/tree/master">web scraper</a> on Github to extract Yahoo! News articles summary based on search criteria. Using the scraper, we extracted the articles and the corresponding links related to <strong>NVIDIA</strong>. </p>
<h2>Actual Scraping</h2>
<p>Here it's the Python code for scraping Headlines, Sources, Posted, Descriptions, and Links.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">re</span><span class="o">,</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="c1">#making HTTP requests to the website and imitating a web browser.</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;accept&#39;</span><span class="p">:</span> <span class="s1">&#39;*/*&#39;</span><span class="p">,</span>
    <span class="s1">&#39;accept-encoding&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip, deflate, br&#39;</span><span class="p">,</span>
    <span class="s1">&#39;accept-language&#39;</span><span class="p">:</span> <span class="s1">&#39;en-US,en;q=0.9&#39;</span><span class="p">,</span>
    <span class="s1">&#39;referer&#39;</span><span class="p">:</span> <span class="s1">&#39;https://www.google.com&#39;</span><span class="p">,</span>
    <span class="s1">&#39;user-agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36 Edg/85.0.564.44&#39;</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">get_article</span><span class="p">(</span><span class="n">card</span><span class="p">):</span> <span class="c1">#It takes a `card` as input, which represents an article on the webpage.</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract article information from the raw html&quot;&quot;&quot;</span>
    <span class="n">headline</span> <span class="o">=</span> <span class="n">card</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;h4&#39;</span><span class="p">,</span> <span class="s1">&#39;s-title&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">card</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;span&quot;</span><span class="p">,</span> <span class="s1">&#39;s-source&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">posted</span> <span class="o">=</span> <span class="n">card</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">,</span> <span class="s1">&#39;s-time&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;·&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">description</span> <span class="o">=</span> <span class="n">card</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="s1">&#39;s-desc&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">raw_link</span> <span class="o">=</span> <span class="n">card</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span>
    <span class="n">unquoted_link</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">unquote</span><span class="p">(</span><span class="n">raw_link</span><span class="p">)</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;RU=(.+)\/RK&#39;</span><span class="p">)</span>
    <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">unquoted_link</span><span class="p">)</span>
    <span class="n">clean_link</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">match</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="n">article</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Headline&#39;</span><span class="p">:</span> <span class="n">headline</span><span class="p">,</span>
        <span class="s1">&#39;Source&#39;</span><span class="p">:</span> <span class="n">source</span><span class="p">,</span>
        <span class="s1">&#39;Posted&#39;</span><span class="p">:</span> <span class="n">posted</span><span class="p">,</span>
        <span class="s1">&#39;Description&#39;</span><span class="p">:</span> <span class="n">description</span><span class="p">,</span>
        <span class="s1">&#39;Link&#39;</span><span class="p">:</span> <span class="n">clean_link</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">article</span>

<span class="k">def</span> <span class="nf">get_the_news</span><span class="p">(</span><span class="n">search</span><span class="p">):</span>
<span class="c1">#This function takes a `search` term as input and is the main part of the program.</span>
<span class="c1">#It starts a loop to iterate through multiple pages of search results.</span>
<span class="c1">#Inside the loop, it sends a GET request to the URL and parses the HTML response using BeautifulSoup.</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run the main program&quot;&quot;&quot;</span>
    <span class="n">template</span> <span class="o">=</span> <span class="s1">&#39;https://news.search.yahoo.com/search?p=</span><span class="si">{}</span><span class="s1">&#39;</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">search</span><span class="p">)</span>
    <span class="n">articles</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">links</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
        <span class="n">cards</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="s1">&#39;NewsArticle&#39;</span><span class="p">)</span>
        <span class="c1"># extract articles from page</span>
        <span class="k">for</span> <span class="n">card</span> <span class="ow">in</span> <span class="n">cards</span><span class="p">:</span>
<span class="c1">#Checks if the extracted link is not already in the set of links and adds the article to the `articles` list.</span>
            <span class="n">article</span> <span class="o">=</span> <span class="n">get_article</span><span class="p">(</span><span class="n">card</span><span class="p">)</span>
            <span class="n">link</span> <span class="o">=</span> <span class="n">article</span><span class="p">[</span><span class="s1">&#39;Link&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">link</span> <span class="ow">and</span> <span class="n">link</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
                <span class="n">links</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
                <span class="n">articles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">article</span><span class="p">)</span>

<span class="c1">#The loop continues until there are no more pages of search results.</span>
<span class="c1"># find the next page, and it introduces a delay of 1 second before making the next request to avoid overwhelming the website.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;next&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span>
            <span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">break</span>
<span class="c1">#Finally, it saves the article data in a CSV file named &quot;results.csv&quot; and returns the list of articles.</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;results.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">articles</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerows</span><span class="p">(</span><span class="n">articles</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">articles</span>

<span class="n">articles</span> <span class="o">=</span> <span class="n">get_the_news</span><span class="p">(</span><span class="s1">&#39;Nvidia&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span><span class="c1">#prints a line of dashes as a separator to visually separate each article&#39;s information.</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Headline: </span><span class="si">{</span><span class="n">article</span><span class="p">[</span><span class="s1">&#39;Headline&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="c1"># prints the headline of the article using an f-string to include the value of `article[&#39;Headline&#39;]`.</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Source: </span><span class="si">{</span><span class="n">article</span><span class="p">[</span><span class="s1">&#39;Source&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="c1">#prints the source of the article using an f-string to include the value of `article[&#39;Source&#39;]`.</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Posted: </span><span class="si">{</span><span class="n">article</span><span class="p">[</span><span class="s1">&#39;Posted&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="c1">#prints the posted date of the article using an f-string to include the value of `article[&#39;Posted&#39;]`.</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Description: </span><span class="si">{</span><span class="n">article</span><span class="p">[</span><span class="s1">&#39;Description&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="c1">#prints the description of the article using an f-string to include the value of `article[&#39;Description&#39;]`.</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Link: </span><span class="si">{</span><span class="n">article</span><span class="p">[</span><span class="s1">&#39;Link&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="c1">#prints the link of the article using an f-string to include the value of `article[&#39;Link&#39;]`.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
</code></pre></div>

<p>744 news articles regarding Nvidia have been posted on Yahoo and are stored in a CSV file. We have mainly gathered links, descriptions and headlines. Our next step would be using the collected links to scrape each articles' text, which will be helpful for sentiment analysis.</p>
<h1>Washington Post</h1>
<h2>Scraping with Apify</h2>
<p>We have also utilized a online platform named <strong>Apify</strong> to help us to scrape the data from Washington Post. However, a limitation of it is that we were not able set a filter to only collect the news related to <strong>NVIDIA</strong>. We found a work-around by only scraping the articles under <a href="https://www.washingtonpost.com/technology/">Technology</a>. With the results, we can further filter out the articles related to our target.</p>
<p><em>A snapshot of the working Apify scraper - Scope set as all tech-related news after 2024-01-01</em>:
<img alt="Figure 7" src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/images/NextLevelPro_01_07WPonApify.jpg"></p>
<p>We can see that the scraper sucessfully retrieved the <code>Title</code>, <code>Description</code> and <code>Text</code> of each article. These results can then be exported to <code>csv</code> for our further handling. For the time being, we have scraped the articles after 2024-01-01 on Washington Post using this tool.</p>
<h1>Next Step</h1>
<h2>Text Analysis</h2>
<p>We will continue to explore other data sources and assess their abundance of articles related to our target, as well as their accessibility. We aim to scrape from 1 or 2 more websites to allow our data sources to be more diversified. </p>
<p>After that, we will explore the use of different Text Sentiment Analyzers. We will try focus on using <a href="https://pypi.org/project/NewsSentiment/">NewsSentiment</a> as it is an easy-to-use Python library that achieves state-of-the-art performance for target-dependent sentiment classification on news articles. </p>
<h2>Collection of Y-values and model building</h2>
<p>We will also work on collecting the necessary Y-values and explore various machine learning/ deep learning models to proceed with the project. </p>
<p>In particular, we intend to employ the data of Average True Range (ATR) and standard deviation as metrics to measure volatility, which serve as the necessary Y-values required to proceed this project. Average True Range (ATR) and standard deviation are both widely recognized measures of volatility in finance. </p>
<p><strong>Average True Range (ATR):</strong> ATR is a technical analysis indicator that measures market volatility by calculating the average range of price movements over a specified period. It takes into account the highs, lows, and closing prices of an asset, reflecting the degree of price fluctuations. Since ATR accounts for the extent of price changes, it provides a comprehensive view of the market's volatility, making it a useful tool for assessing risk and determining stop-loss levels.</p>
<p>We employ the Average True Range (ATR) to reflect the true price fluctuations over a specific period. Let <span class="math">\(H_t\)</span>, <span class="math">\(L_t\)</span>, and <span class="math">\(C_t\)</span> denote the highest price, lowest price, and closing price on day <span class="math">\(t\)</span>, respectively; then ATR is defined as follows:</p>
<p><span class="math">\(TR_t = max(\frac{H_t-L_t}{C_{t-1}}, \frac{abs(H_t-C_{t-1})}{C_{t-1}}, \frac{abs(C_{t-1}-L_t)}{C_{t-1}})\)</span></p>
<p><span class="math">\(ATR_{10, t} = \displaystyle \sum_{i=1}^{9}{\frac{TR_{t-1}}{10}}\)</span></p>
<p><em>Note: In order to compile the formulas correctly, you may need to install the necessary plugin by running the following command in the terminal:</em></p>
<div class="highlight"><pre><span></span><code>python -m pip install pelican-render-math.
</code></pre></div>

<p><strong>Standard Deviation:</strong> Standard deviation is a statistical measure that quantifies the dispersion of a set of data points, such as the returns of a financial asset. In the context of finance, standard deviation is often used to gauge the volatility of an asset's returns. By measuring the deviation of returns from their mean, standard deviation offers valuable insights into the risk associated with an asset, helping investors make informed decisions regarding their investment strategies.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2024-03-03T21:00:00+08:00">Sun 03 March 2024</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/categories.html#progress-report-1-ref">Progress Report 1</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/tags.html#next-level-pro-ref">Next Level Pro
                    <span class="superscript">2</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/MFIN7036-student-blog-2024-02" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/MFIN7036-student-blog-2024-02/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>